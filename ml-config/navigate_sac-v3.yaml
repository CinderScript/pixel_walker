# Configuration is based on the hyperparameters for "Pyramids"
# ml-agents example project found at:
# https://github.com/Unity-Technologies/ml-agents/blob/release_19_docs/docs/Learning-Environment-Examples.md


behaviors:
  Navigate:
    trainer_type: sac

    hyperparameters:
      learning_rate: 0.0003
      learning_rate_schedule: constant
      batch_size: 256
      buffer_size: 3000000
      buffer_init_steps: 1000
      tau: 0.01
      steps_per_update: 10.0
      save_replay_buffer: false
      init_entcoef: 0.01
      reward_signal_steps_per_update: 10.0

    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
      vis_encode_type: simple

    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 2.0

    keep_checkpoints: 5
    max_steps: 3000000
    time_horizon: 128
    summary_freq: 30000


engine_settings:
  width: 84
  height: 84
  quality_level: 0
  time_scale: 30
  target_frame_rate: -1
  capture_frame_rate: 60
  no_graphics: true