# Configuration is based on the hyperparameters for "Pyramids"
# ml-agents example project found at:
# https://github.com/Unity-Technologies/ml-agents/blob/release_19_docs/docs/Learning-Environment-Examples.md


behaviors:
  Navigate:
    trainer_type: sac

    hyperparameters:
      learning_rate: 0.0003
      learning_rate_schedule: constant
      batch_size: 256
      buffer_size: 3000000
      buffer_init_steps: 1000
      tau: 0.01
      steps_per_update: 10.0
      save_replay_buffer: false
      init_entcoef: 0.01
      reward_signal_steps_per_update: 10.0

    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
      vis_encode_type: simple

    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 2.0

    keep_checkpoints: 5
    max_steps: 30e6
    time_horizon: 128
    summary_freq: 30000

environment_parameters:
  collision_penalty:
    curriculum:
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: Navigate       # next behavior
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 2
        value: -0.004

      - name: Lesson2
        completion_criteria:
          measure: reward
          behavior: Navigate
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 3.0
        value: -0.008

      - name: Lesson3
        completion_criteria:
          measure: reward
          behavior: Navigate
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 4.0
        value: -0.015

      - name: Lesson4
        completion_criteria:
          measure: reward
          behavior: Navigate
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 4.5
        value: -0.015
      - name: Lesson5
        value: -0.04

engine_settings:
  width: 84
  height: 84
  quality_level: 0
  time_scale: 10
  target_frame_rate: -1
  capture_frame_rate: 60
  no_graphics: true